FrostE Phase 1: Transitioning UGV Beast to Vision-Only AutonomyObjective: Achieve "Room-Scale Autonomy" using only the OAK-D Pro camera.Success Criteria: The robot can map a room, save the map, and autonomously navigate to a goal point selected in RViz, without using LiDAR.Source Codebase: ugv_ws1. Repository Cleanup & Structure AnalysisWe will perform "surgical" edits to the existing ugv_ws to create our froste variants. We will not delete the original files but create copies with the froste_ prefix to maintain a fallback.Target Package Modification:Keep: ugv_base_node (Keep as is. It handles the critical Odom+IMU fusion).Modify: ugv_bringup, ugv_vision, ugv_slam, ugv_nav.Ignore: ugv_chat_ai, ugv_web_app (These are bloat for this milestone).2. Step 1: The Driver & Camera (The "Body")We need a launch file that brings up the robot without the LiDAR and with the OAK-D Pro active stereo enabled.2.1 Configure OAK-D Pro for "White Wall" MappingThe default oak_d_lite.launch.py is insufficient because the Lite lacks the IR projector. The Pro needs the projector enabled to see depth on featureless indoor walls.Action: Create src/ugv_main/ugv_vision/launch/froste_camera.launch.pyThis should wrap the standard depthai_ros_driver but inject specific parameters.Python# Key Parameter Changes for OAK-D Pro
parameters =
2.2 Create the FrostE BringupWe must replace bringup_imu_ekf.launch.py. The original launches ldlidar. If we leave that running, it will publish empty or error-filled transforms/scans that will confuse the Nav stack.Action: Create src/ugv_main/ugv_bringup/launch/froste_bringup.launch.pyInclude: ugv_bringup/launch/driver.launch.py (Motor Control).Include: ugv_base_node/launch/base_node.launch.py (Odometry Fusion).Include: ugv_vision/launch/froste_camera.launch.py (The new camera launch).REMOVE: Any reference to ldlidar.REMOVE: robot_localization (EKF) if you plan to let RTAB-Map handle odom->map. However, ugv_ws uses EKF to fuse Wheel+IMU into /odom. Keep the EKF, but ensure it doesn't wait for LiDAR.3. Step 2: RTAB-Map Configuration (The "Mapper")We need to configure RTAB-Map to act as our SLAM engine and our LiDAR emulator. It must ingest depth images and output a 2D Occupancy Grid.Action: Create src/ugv_main/ugv_slam/launch/froste_mapping.launch.pyCopy rtabmap_rgbd.launch.py and modify the arguments passed to the rtabmap node.Critical Parameter Overrides:subscribe_scan: false (We have no LiDAR).subscribe_depth: true.frame_id: base_footprint (Ensure this matches the URDF).map_frame_id: map.visual_odometry: false (We trust the ugv_base_node EKF odometry more than pure visual odometry for this chassis).odom_topic: /odom (From ugv_base_node).RTAB-Map Internal Args (rtabmap_args):These are the "Magic Numbers" for LiDAR-less mapping.--Grid/FromDepth true: The most important setting. Tells RTAB-Map to raytrace the 3D depth cloud to create the 2D map.--Reg/Force3DoF true: Forces the graph optimizer to ignore Roll/Pitch/Z. Keeps the map flat even if the robot hits a bump.--Grid/RayTracing true: Clears empty space. Essential for navigation; otherwise, dynamic obstacles (like people) become permanent walls.Verification (RVIZ):Launch froste_mapping.launch.py.Open RViz.Add display -> Map -> Topic /map (or /grid_map).Test: Drive the robot toward a wall. Does the map show a black line appearing where the wall is? If yes, the depth-to-scan projection is working.4. Step 3: Map Saving (The "Artifact")The ugv_ws repo uses a script save_2d_gmapping_map.sh. We will adapt this.Action: Create save_froste_map.sh in the root workspace.Bash#!/bin/bash
# Save the map using the standard Nav2 map_saver
ros2 run nav2_map_server map_saver_cli -f ~/froste_ws/src/ugv_main/ugv_nav/maps/my_room
Note: Run this while the mapping node is still running. It grabs the current /map topic and saves my_room.pgm and my_room.yaml.5. Step 4: Navigation (The "Navigator")This is the hardest part. The default nav2_params.yaml in ugv_nav is tuned for LiDAR. A LiDAR ObstacleLayer expects a LaserScan. If we give it nothing, the robot will be blind to new obstacles.Action: Create src/ugv_main/ugv_nav/param/froste_nav2_params.yaml5.1 Modifying the CostmapsWe need to switch from a 2D Laser Layer to a 3D Voxel Layer (or a Depth Observation Layer).Local Costmap Config:YAMLlocal_costmap:
  local_costmap:
    ros__parameters:
      plugins: ["voxel_layer", "inflation_layer"]
      voxel_layer:
        plugin: "nav2_costmap_2d::VoxelLayer"
        enabled: True
        observation_sources: pointcloud
        pointcloud:
          topic: /camera/points  # CHECK THIS TOPIC NAME via 'ros2 topic list'
          max_obstacle_height: 2.0
          min_obstacle_height: 0.1
          clearing: True
          marking: True
          data_type: "PointCloud2"
Why? This allows the robot to "see" chairs and tables using the depth camera for obstacle avoidance, even if they aren't on the static map.5.2 Switching LocalizationThe ugv_nav launch likely starts amcl (Adaptive Monte Carlo Localization). AMCL requires a LaserScan. It will not work for us. We must disable AMCL and use RTAB-Map in localization mode.Action: Create src/ugv_main/ugv_nav/launch/froste_nav.launch.pyDo not launch amcl.Launch rtabmap_rgbd.launch.py (from Step 2) but add argument localization:=true.This puts RTAB-Map in read-only mode. It will publish the map -> odom transform based on visual loop closures.Launch nav2_bringup (lifecycle manager, planner, controller) pointing to froste_nav2_params.yaml.6. Execution Sequence (Milestone 1 Complete)Session A: Mappingros2 launch froste_bringup froste_bringup.launch.py (Starts Driver + OAK-D Pro)ros2 launch froste_bringup froste_mapping.launch.py (Starts RTAB-Map in Mapping Mode)Drive: Use the joystick/keyboard to paint the room. Perform 360 spins at corners.Save: Run ./save_froste_map.sh.Shutdown: Ctrl-C everything.Session B: Navigationros2 launch froste_bringup froste_bringup.launch.pyros2 launch froste_bringup froste_nav.launch.py (Starts RTAB-Map Localization + Nav2)Wake Up: The robot may not know where it is initially. Drive forward slightly until RTAB-Map recognizes a visual feature. The map should "snap" into place in RViz.Command: Use "2D Nav Goal" in RViz. Click a point on the map.Observe: The robot should plan a path (Global Planner) and drive to it (Local Planner), avoiding obstacles seen by the depth camera.